{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"    ","metadata":{"papermill":{"duration":0.049622,"end_time":"2022-07-03T10:32:34.054102","exception":false,"start_time":"2022-07-03T10:32:34.004480","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"    ","metadata":{"papermill":{"duration":0.054195,"end_time":"2022-07-03T10:32:34.260232","exception":false,"start_time":"2022-07-03T10:32:34.206037","status":"completed"},"tags":[]}},{"cell_type":"code","source":"### **Variables**\n\n#### 1. X\n#### 2. Y\n#### 3. Z\n#### 4. Cluster ID\n\n","metadata":{"papermill":{"duration":0.054325,"end_time":"2022-07-03T10:32:34.375007","exception":false,"start_time":"2022-07-03T10:32:34.320682","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-26T14:45:40.572083Z","iopub.execute_input":"2022-08-26T14:45:40.572395Z","iopub.status.idle":"2022-08-26T14:45:40.575968Z","shell.execute_reply.started":"2022-08-26T14:45:40.572360Z","shell.execute_reply":"2022-08-26T14:45:40.575311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Objective:\n\n#### Reduce X,Y,Z column to two column (d1, d2) using dimensionality reduction techniques (you can use any known techniques) . ","metadata":{"papermill":{"duration":0.048864,"end_time":"2022-07-03T10:32:34.472655","exception":false,"start_time":"2022-07-03T10:32:34.423791","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom plotnine import *\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.cluster import KMeans, AgglomerativeClustering\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import cross_validate\nfrom scipy.stats import boxcox, shapiro, probplot\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nimport statsmodels.api as sm\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning) ","metadata":{"papermill":{"duration":3.40085,"end_time":"2022-07-03T10:32:37.922604","exception":false,"start_time":"2022-07-03T10:32:34.521754","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:18:28.685803Z","iopub.execute_input":"2022-08-30T03:18:28.686023Z","iopub.status.idle":"2022-08-30T03:18:28.692103Z","shell.execute_reply.started":"2022-08-30T03:18:28.686000Z","shell.execute_reply":"2022-08-30T03:18:28.691118Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"<h1><center><a id=\"2\"></a> <br> Data Preprocessing</center></h1>","metadata":{"execution":{"iopub.execute_input":"2022-05-01T22:07:59.423382Z","iopub.status.busy":"2022-05-01T22:07:59.423049Z","iopub.status.idle":"2022-05-01T22:07:59.429422Z","shell.execute_reply":"2022-05-01T22:07:59.428262Z","shell.execute_reply.started":"2022-05-01T22:07:59.423347Z"},"papermill":{"duration":0.050033,"end_time":"2022-07-03T10:32:38.022542","exception":false,"start_time":"2022-07-03T10:32:37.972509","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Download the data","metadata":{"papermill":{"duration":0.049804,"end_time":"2022-07-03T10:32:38.122756","exception":false,"start_time":"2022-07-03T10:32:38.072952","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df=pd.read_csv(\"../input/distance-dataset/distance_dataset.csv\")","metadata":{"papermill":{"duration":0.068277,"end_time":"2022-07-03T10:32:38.241892","exception":false,"start_time":"2022-07-03T10:32:38.173615","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:18:16.441183Z","iopub.execute_input":"2022-08-30T03:18:16.441381Z","iopub.status.idle":"2022-08-30T03:18:16.449313Z","shell.execute_reply.started":"2022-08-30T03:18:16.441359Z","shell.execute_reply":"2022-08-30T03:18:16.448687Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"papermill":{"duration":0.071845,"end_time":"2022-07-03T10:32:38.363915","exception":false,"start_time":"2022-07-03T10:32:38.292070","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:18:35.079995Z","iopub.execute_input":"2022-08-30T03:18:35.080228Z","iopub.status.idle":"2022-08-30T03:18:35.089119Z","shell.execute_reply.started":"2022-08-30T03:18:35.080205Z","shell.execute_reply":"2022-08-30T03:18:35.088703Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#Checking for nulls\n\ndf.isnull().sum()","metadata":{"papermill":{"duration":0.061852,"end_time":"2022-07-03T10:32:38.476526","exception":false,"start_time":"2022-07-03T10:32:38.414674","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:18:37.718914Z","iopub.execute_input":"2022-08-30T03:18:37.719232Z","iopub.status.idle":"2022-08-30T03:18:37.724904Z","shell.execute_reply.started":"2022-08-30T03:18:37.719209Z","shell.execute_reply":"2022-08-30T03:18:37.724286Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#No nulls -great\n\n#Checking for data types\n\ndf.info()\n","metadata":{"papermill":{"duration":0.077107,"end_time":"2022-07-03T10:32:38.604518","exception":false,"start_time":"2022-07-03T10:32:38.527411","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:18:39.855562Z","iopub.execute_input":"2022-08-30T03:18:39.855834Z","iopub.status.idle":"2022-08-30T03:18:39.865541Z","shell.execute_reply.started":"2022-08-30T03:18:39.855810Z","shell.execute_reply":"2022-08-30T03:18:39.864857Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#Statistical summary\n\ndf.describe()","metadata":{"papermill":{"duration":0.091388,"end_time":"2022-07-03T10:32:38.748392","exception":false,"start_time":"2022-07-03T10:32:38.657004","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:18:42.200170Z","iopub.execute_input":"2022-08-30T03:18:42.200408Z","iopub.status.idle":"2022-08-30T03:18:42.221137Z","shell.execute_reply.started":"2022-08-30T03:18:42.200383Z","shell.execute_reply":"2022-08-30T03:18:42.220456Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"##We can clearly see that the data is not scaled and not normally distributed. We will examine thus further ahead.","metadata":{"papermill":{"duration":0.052306,"end_time":"2022-07-03T10:32:38.853298","exception":false,"start_time":"2022-07-03T10:32:38.800992","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#LetÂ´s convert the categorical variables to meaningful data\n\ndf.X.value_counts()","metadata":{"papermill":{"duration":0.062755,"end_time":"2022-07-03T10:32:38.968356","exception":false,"start_time":"2022-07-03T10:32:38.905601","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:18:46.175331Z","iopub.execute_input":"2022-08-30T03:18:46.175577Z","iopub.status.idle":"2022-08-30T03:18:46.182818Z","shell.execute_reply.started":"2022-08-30T03:18:46.175550Z","shell.execute_reply":"2022-08-30T03:18:46.182115Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df.X=df.X.map({3:'Other',2:'Lisbon',1:'Oporto'})","metadata":{"papermill":{"duration":0.061221,"end_time":"2022-07-03T10:32:39.082071","exception":false,"start_time":"2022-07-03T10:32:39.020850","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:18:51.045227Z","iopub.execute_input":"2022-08-30T03:18:51.045501Z","iopub.status.idle":"2022-08-30T03:18:51.051957Z","shell.execute_reply.started":"2022-08-30T03:18:51.045478Z","shell.execute_reply":"2022-08-30T03:18:51.050923Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"df.Y.value_counts()","metadata":{"papermill":{"duration":0.062221,"end_time":"2022-07-03T10:32:39.196750","exception":false,"start_time":"2022-07-03T10:32:39.134529","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:18:52.790416Z","iopub.execute_input":"2022-08-30T03:18:52.790709Z","iopub.status.idle":"2022-08-30T03:18:52.799551Z","shell.execute_reply.started":"2022-08-30T03:18:52.790676Z","shell.execute_reply":"2022-08-30T03:18:52.798790Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df.Y=df.Y.map({1:'Horeca',2:'Retail'})","metadata":{"papermill":{"duration":0.062293,"end_time":"2022-07-03T10:32:39.312136","exception":false,"start_time":"2022-07-03T10:32:39.249843","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-26T14:26:37.270554Z","iopub.execute_input":"2022-08-26T14:26:37.271314Z","iopub.status.idle":"2022-08-26T14:26:37.277717Z","shell.execute_reply.started":"2022-08-26T14:26:37.271256Z","shell.execute_reply":"2022-08-26T14:26:37.276814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of numeric variables\n\ndf.hist(figsize=(20,10),bins=30, color='lightblue', edgecolor='black')\nplt.show()","metadata":{"papermill":{"duration":1.117581,"end_time":"2022-07-03T10:32:40.482170","exception":false,"start_time":"2022-07-03T10:32:39.364589","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:18:55.670484Z","iopub.execute_input":"2022-08-30T03:18:55.670730Z","iopub.status.idle":"2022-08-30T03:18:56.422309Z","shell.execute_reply.started":"2022-08-30T03:18:55.670705Z","shell.execute_reply":"2022-08-30T03:18:56.421692Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"##susceptible to influential outlying values - they can strongly bias the centroids estimation. \n##In a situation like ##this K-Medians might be advisable. However data might be transformed also. \n##Here we will deploy the Box-Cox method. It ##can be implemented via ScikitLearn PowerTransformer() \n##function or with the help of box-cox from Scipy Stats library. ##We will choose the second option.","metadata":{"papermill":{"duration":0.055029,"end_time":"2022-07-03T10:32:40.591014","exception":false,"start_time":"2022-07-03T10:32:40.535985","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:18:59.652684Z","iopub.execute_input":"2022-08-30T03:18:59.652923Z","iopub.status.idle":"2022-08-30T03:18:59.656988Z","shell.execute_reply.started":"2022-08-30T03:18:59.652898Z","shell.execute_reply":"2022-08-30T03:18:59.656220Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#Now the data resembles more the normal distribution\n\ndf.hist(figsize=(20,10),bins=30, color='lightblue', edgecolor='black')\nplt.show()","metadata":{"papermill":{"duration":1.211833,"end_time":"2022-07-03T10:32:42.002803","exception":false,"start_time":"2022-07-03T10:32:40.790970","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:19:16.572292Z","iopub.execute_input":"2022-08-30T03:19:16.572493Z","iopub.status.idle":"2022-08-30T03:19:17.205437Z","shell.execute_reply.started":"2022-08-30T03:19:16.572470Z","shell.execute_reply":"2022-08-30T03:19:17.205028Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"##Also we need to scale the data so the distance analysis across dimensions won't be biased. KMeans performs the \n##analysis on the same scale between variables and therefore unscaled data will lead to biased learning. \n ","metadata":{"papermill":{"duration":0.05605,"end_time":"2022-07-03T10:32:42.114751","exception":false,"start_time":"2022-07-03T10:32:42.058701","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"norm=df.iloc[:,2:] #Numerical data\n\nscaler=MinMaxScaler()\ncolumns=df.columns[2:]\nnorm=scaler.fit_transform(df.iloc[:,2:]) #Only numeric variables\nnorm=pd.DataFrame(norm, columns=columns)\n\nplt.figure(figsize=(10,7))\nsns.boxplot(data=norm)\nplt.show()","metadata":{"papermill":{"duration":0.305554,"end_time":"2022-07-03T10:32:42.475423","exception":false,"start_time":"2022-07-03T10:32:42.169869","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:19:59.661566Z","iopub.execute_input":"2022-08-30T03:19:59.661857Z","iopub.status.idle":"2022-08-30T03:19:59.802129Z","shell.execute_reply.started":"2022-08-30T03:19:59.661808Z","shell.execute_reply":"2022-08-30T03:19:59.801556Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"##As already mentioned may negatively affect the calculation of cluster centers as individual outliers may have a \n##lot of weight in determing cluster means. Therefore we will move the outliers to 1.5 of Interquartile range \n##from 1st or 3rd quartile.","metadata":{"papermill":{"duration":0.057821,"end_time":"2022-07-03T10:32:42.591295","exception":false,"start_time":"2022-07-03T10:32:42.533474","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-30T03:20:03.308686Z","iopub.execute_input":"2022-08-30T03:20:03.308906Z","iopub.status.idle":"2022-08-30T03:20:03.312400Z","shell.execute_reply.started":"2022-08-30T03:20:03.308882Z","shell.execute_reply":"2022-08-30T03:20:03.311714Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"for i in norm.columns:\n    iqr=np.percentile(norm[i], 75)-np.percentile(norm[i], 25)\n    per75=np.percentile(norm[i], 75)\n    per25=np.percentile(norm[i], 25)\n    norm[i]=np.where(norm[i]>per75+1.5*iqr, per75+1.5*iqr,norm[i] )\n    norm[i]=np.where(norm[i]<per25-1.5*iqr, per25-1.5*iqr,norm[i] )","metadata":{"papermill":{"duration":0.076827,"end_time":"2022-07-03T10:32:42.725041","exception":false,"start_time":"2022-07-03T10:32:42.648214","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:20:05.032090Z","iopub.execute_input":"2022-08-30T03:20:05.032306Z","iopub.status.idle":"2022-08-30T03:20:05.041810Z","shell.execute_reply.started":"2022-08-30T03:20:05.032279Z","shell.execute_reply":"2022-08-30T03:20:05.041114Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#Now we donÂ´t have outliers\n\nplt.figure(figsize=(15,10))\nsns.boxplot(data=norm)\nplt.show()","metadata":{"papermill":{"duration":0.308831,"end_time":"2022-07-03T10:32:43.090085","exception":false,"start_time":"2022-07-03T10:32:42.781254","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:20:08.866062Z","iopub.execute_input":"2022-08-30T03:20:08.866380Z","iopub.status.idle":"2022-08-30T03:20:09.016944Z","shell.execute_reply.started":"2022-08-30T03:20:08.866355Z","shell.execute_reply":"2022-08-30T03:20:09.016278Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"#LetÂ´s also check for normality of the numeric variables now. However it is not a required assumptions \n#of KMeans but can produce better results. Shapiro Wilks test may be employed. \n#The null hypothesis is that the data is normal.\n\n\n\nnormality=pd.DataFrame(index=['p-value', 'test-statistic'])\nfor i in norm.columns:\n    normality[i]=shapiro(norm[i])\n    \nnormality.T    ","metadata":{"papermill":{"duration":0.074436,"end_time":"2022-07-03T10:32:43.222131","exception":false,"start_time":"2022-07-03T10:32:43.147695","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:20:14.154921Z","iopub.execute_input":"2022-08-30T03:20:14.155134Z","iopub.status.idle":"2022-08-30T03:20:14.166329Z","shell.execute_reply.started":"2022-08-30T03:20:14.155110Z","shell.execute_reply":"2022-08-30T03:20:14.165823Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#We can also plot the normality via que quantile quantile plots from scipy statistical library.\n\nplt.figure(figsize=(15,15))\nfor i,var in enumerate(norm.columns):\n    plt.subplot(3,3,i+1)\n    probplot(norm[var], plot=plt)\n    plt.title(f'{var}')\nplt.show()    ","metadata":{"papermill":{"duration":0.811536,"end_time":"2022-07-03T10:32:44.092203","exception":false,"start_time":"2022-07-03T10:32:43.280667","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:20:16.838137Z","iopub.execute_input":"2022-08-30T03:20:16.838416Z","iopub.status.idle":"2022-08-30T03:20:17.171070Z","shell.execute_reply.started":"2022-08-30T03:20:16.838392Z","shell.execute_reply":"2022-08-30T03:20:17.170607Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"##We can see that the data is not normally distributed. Additionally, we have two categorical variables, \n##Region and Channel that have to be recoded (One Hot Encoding) for further analysis as not to cause incorrect \n##distance estimations in distance/based algorithms. KMeans may be not stable while working on a mix of numerical \n##and categorical data. How we define distance between the values in the Region variable? The right way in my opinion \n##will be Hot Encoding","metadata":{"papermill":{"duration":0.059391,"end_time":"2022-07-03T10:32:44.212170","exception":false,"start_time":"2022-07-03T10:32:44.152779","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-08-30T03:20:20.019266Z","iopub.execute_input":"2022-08-30T03:20:20.019515Z","iopub.status.idle":"2022-08-30T03:20:20.024034Z","shell.execute_reply.started":"2022-08-30T03:20:20.019489Z","shell.execute_reply":"2022-08-30T03:20:20.023059Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"data=pd.get_dummies(data=df, columns= ['X','Z'], drop_first=True)\n\n#Uniting our categorical dummified variables with numerical normalized data.\n\n","metadata":{"papermill":{"duration":0.074899,"end_time":"2022-07-03T10:32:44.349763","exception":false,"start_time":"2022-07-03T10:32:44.274864","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:20:25.734421Z","iopub.execute_input":"2022-08-30T03:20:25.734903Z","iopub.status.idle":"2022-08-30T03:20:25.768588Z","shell.execute_reply.started":"2022-08-30T03:20:25.734876Z","shell.execute_reply":"2022-08-30T03:20:25.767916Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"<h1><center><a id=\"3\"></a> <br>Modelling and Analysis</center></h1>","metadata":{"execution":{"iopub.execute_input":"2022-05-01T22:57:43.829512Z","iopub.status.busy":"2022-05-01T22:57:43.829221Z","iopub.status.idle":"2022-05-01T22:57:43.850312Z","shell.execute_reply":"2022-05-01T22:57:43.849349Z","shell.execute_reply.started":"2022-05-01T22:57:43.829482Z"},"papermill":{"duration":0.059363,"end_time":"2022-07-03T10:32:44.469137","exception":false,"start_time":"2022-07-03T10:32:44.409774","status":"completed"},"tags":[]}},{"cell_type":"code","source":"##We are ready to perform the KMeans. However how many clusters should we choose? We have to determine the best number \n##of clusters. This can be done using \"elbow trick\". We will calculate WSS - Within Sum \n##of Squares (of the distances inside the cluster) for each option of number of clusters while the goal is \n##find a number of clusters which minimizes considerably the WSS. We will examine WSS between 2 and 10 clusters. ","metadata":{"papermill":{"duration":0.05965,"end_time":"2022-07-03T10:32:44.588379","exception":false,"start_time":"2022-07-03T10:32:44.528729","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elbow_results=[]\nfor i in range(3,2):\n    kmeans=KMeans(init='k-means++' , n_clusters=i, random_state=0)\n    results=cross_validate(kmeans, data, cv=5)\n    elbow_results.append(results['test_score'].mean()*-1)","metadata":{"papermill":{"duration":1.914926,"end_time":"2022-07-03T10:32:46.563484","exception":false,"start_time":"2022-07-03T10:32:44.648558","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:20:30.160170Z","iopub.execute_input":"2022-08-30T03:20:30.160403Z","iopub.status.idle":"2022-08-30T03:20:30.164678Z","shell.execute_reply.started":"2022-08-30T03:20:30.160379Z","shell.execute_reply":"2022-08-30T03:20:30.164050Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"\nplt.plot(range(2,len(elbow_results)+2) , elbow_results)\nplt.title('WSS - Elbow number of clusters test')\nplt.xlabel('Number of Clusters')\nplt.ylabel('Within Clusters Sum of Squares')\nplt.show()","metadata":{"papermill":{"duration":0.255287,"end_time":"2022-07-03T10:32:46.881370","exception":false,"start_time":"2022-07-03T10:32:46.626083","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:20:35.698235Z","iopub.execute_input":"2022-08-30T03:20:35.698527Z","iopub.status.idle":"2022-08-30T03:20:35.845057Z","shell.execute_reply.started":"2022-08-30T03:20:35.698492Z","shell.execute_reply":"2022-08-30T03:20:35.844492Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"##Plotting the elbow we can see that it's formed at value 3 on the X-axis. It means that having 3 clusters will \n##obtain the greatest proportional change in minimizing the WSS. However also number 6 presents a viable option as \n##there is a considerable change in sum of distances between 5 and 6 clusters. Adding more clusters will lower the \n##WSS but not at such considerable rate as the change between 2 and 3 clusters or between 5 or 6. Speaking in other \n##words, we are looking for the smallest angle formed by the line on the plot. Now we will try to run the algorithm \n##to group  3 clusters.","metadata":{"papermill":{"duration":0.060311,"end_time":"2022-07-03T10:32:47.003770","exception":false,"start_time":"2022-07-03T10:32:46.943459","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's visualize the clusters via pairs of variables. To do that more efficiently we need to reduce the dimensionality , so we will deploy PCA (Principal Components Analysis). First LetÂ´s determine the best number of components to use in order to capture at least 90% of the variability of the data","metadata":{"papermill":{"duration":0.060366,"end_time":"2022-07-03T10:32:47.285561","exception":false,"start_time":"2022-07-03T10:32:47.225195","status":"completed"},"tags":[]}},{"cell_type":"code","source":"pca=PCA(n_components=len(df.columns)-1)\n\npca.fit(df.iloc[:,:-1])\n\npca.explained_variance_ratio_","metadata":{"papermill":{"duration":0.087368,"end_time":"2022-07-03T10:32:47.433724","exception":false,"start_time":"2022-07-03T10:32:47.346356","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:20:41.716423Z","iopub.execute_input":"2022-08-30T03:20:41.716703Z","iopub.status.idle":"2022-08-30T03:20:41.748857Z","shell.execute_reply.started":"2022-08-30T03:20:41.716652Z","shell.execute_reply":"2022-08-30T03:20:41.747160Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\n\nplt.bar(range(1,2), height=np.cumsum(pca.explained_variance_ratio_), label='Cumulative Explained Variance')\nplt.axhline(y=0.9, c='g', label='Cutoff')\nplt.title('Explained variance in PCA')\nplt.xticks(range(1,10))\nplt.legend(loc=1)\nplt.show()","metadata":{"papermill":{"duration":0.295496,"end_time":"2022-07-03T10:32:47.792019","exception":false,"start_time":"2022-07-03T10:32:47.496523","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-26T14:54:56.518130Z","iopub.execute_input":"2022-08-26T14:54:56.518443Z","iopub.status.idle":"2022-08-26T14:54:56.760304Z","shell.execute_reply.started":"2022-08-26T14:54:56.518408Z","shell.execute_reply":"2022-08-26T14:54:56.759456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##We can see that 90% of explained variability reached when we use 4 components. Therefore we will implement \n##dimensionality reduction to 4 components","metadata":{"papermill":{"duration":0.061984,"end_time":"2022-07-03T10:32:47.916518","exception":false,"start_time":"2022-07-03T10:32:47.854534","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca=PCA(n_components=2)\nreduced=pca.fit_transform(df.iloc[:,:-1])\n\nreduced=pd.dataFrame(np.column_stack([reduced, df.clusters]), columns=['X','Y'])\n\nsns.pairplot(reduced, hue='Cluster', diag_kind=None, vars=reduced.columns[0:-1], palette='Set1')\nplt.show()","metadata":{"papermill":{"duration":4.478262,"end_time":"2022-07-03T10:32:52.457839","exception":false,"start_time":"2022-07-03T10:32:47.979577","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-26T14:59:02.023787Z","iopub.execute_input":"2022-08-26T14:59:02.024071Z","iopub.status.idle":"2022-08-26T14:59:02.076231Z","shell.execute_reply.started":"2022-08-26T14:59:02.024040Z","shell.execute_reply":"2022-08-26T14:59:02.074647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##ItÂ´s difficult to grasp the clusters like that. LetÂ´s perform a component reduction to two variables.","metadata":{"papermill":{"duration":0.067912,"end_time":"2022-07-03T10:32:52.594831","exception":false,"start_time":"2022-07-03T10:32:52.526919","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca=PCA(n_components=2)\nreduced=pca.fit_transform(data.iloc[:,:-1])\nreduced=pd.DataFrame(np.column_stack([reduced, df.clusters]), columns=['Comp1','Comp2','Cluster'])\n\nplt.figure(figsize=(10,10))\nsns.scatterplot(data=reduced, hue='Cluster', x='Comp1',y='Comp2', palette='Set1')\nplt.title('Clusters graphical Representation on data reduced to two dimensions',  fontsize=12)\nplt.show()","metadata":{"papermill":{"duration":0.396514,"end_time":"2022-07-03T10:32:53.061989","exception":false,"start_time":"2022-07-03T10:32:52.665475","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-30T03:20:55.790240Z","iopub.execute_input":"2022-08-30T03:20:55.790517Z","iopub.status.idle":"2022-08-30T03:20:56.314357Z","shell.execute_reply.started":"2022-08-30T03:20:55.790491Z","shell.execute_reply":"2022-08-30T03:20:56.313539Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"##Clearly the clusterization is not looking perfect on two dimensions . Since KMeans works good with spherical forms elongated cluster may present a problem for this centroid-based distance algorithm. It seems that choosing 6 clusters could provide better results.\n\n##LetÂ´s see the means of the original  numerical variable values for different clusters now. ","metadata":{"papermill":{"duration":0.069406,"end_time":"2022-07-03T10:32:53.203340","exception":false,"start_time":"2022-07-03T10:32:53.133934","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"means=df.iloc[:,2:].groupby('clusters').mean()\n\n\nplt.figure(figsize=(10,10))\nmeans.groupby('clusters').mean().plot(kind='bar', figsize=(15,5))\nplt.title('variable means per cluster')\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2022-07-03T10:32:53.345160Z","iopub.status.busy":"2022-07-03T10:32:53.344627Z","iopub.status.idle":"2022-07-03T10:32:53.611191Z","shell.execute_reply":"2022-07-03T10:32:53.610555Z"},"papermill":{"duration":0.339648,"end_time":"2022-07-03T10:32:53.613012","exception":false,"start_time":"2022-07-03T10:32:53.273364","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hierarchy=AgglomerativeClustering(n_clusters=6, affinity='euclidean', linkage='ward', compute_distances=True)\n\ndf['Hierarchical_clusters']=hierarchy.fit_predict(data)","metadata":{"execution":{"iopub.execute_input":"2022-07-03T10:32:53.907142Z","iopub.status.busy":"2022-07-03T10:32:53.906606Z","iopub.status.idle":"2022-07-03T10:32:53.919534Z","shell.execute_reply":"2022-07-03T10:32:53.918579Z"},"papermill":{"duration":0.088753,"end_time":"2022-07-03T10:32:53.921942","exception":false,"start_time":"2022-07-03T10:32:53.833189","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LetÂ´s plot ","metadata":{"papermill":{"duration":0.071755,"end_time":"2022-07-03T10:32:54.065702","exception":false,"start_time":"2022-07-03T10:32:53.993947","status":"completed"},"tags":[]}},{"cell_type":"code","source":"reduced2=pd.DataFrame(np.column_stack([reduced, df['Hierarchical_clusters']]), columns=['Comp1','Comp2','Cluster_K_Means','Hierarchical_Clusters'])","metadata":{"execution":{"iopub.execute_input":"2022-07-03T10:32:54.212643Z","iopub.status.busy":"2022-07-03T10:32:54.212348Z","iopub.status.idle":"2022-07-03T10:32:54.217689Z","shell.execute_reply":"2022-07-03T10:32:54.217098Z"},"papermill":{"duration":0.080655,"end_time":"2022-07-03T10:32:54.219527","exception":false,"start_time":"2022-07-03T10:32:54.138872","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(2,2))\nsns.scatterplot(data=reduced2, hue='Hierarchical_Clusters', x='Comp1',y='Comp2', palette='Set1')\nplt.title('Graphical  clusters representation of data reduced to two dimensions',  fontsize=12)\nplt.show()","metadata":{"papermill":{"duration":0.465338,"end_time":"2022-07-03T10:32:54.757574","exception":false,"start_time":"2022-07-03T10:32:54.292236","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-26T15:00:23.624838Z","iopub.execute_input":"2022-08-26T15:00:23.625145Z","iopub.status.idle":"2022-08-26T15:00:23.654534Z","shell.execute_reply.started":"2022-08-26T15:00:23.625113Z","shell.execute_reply":"2022-08-26T15:00:23.653231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##We can see that the clusters are now formed adequately. But what happens if we want to see what are options \n##in forming clusters, or how the observations will be divided with more or less clusters? We can plot the dendrogram,\n##even before running the Hierarchical clusterization algorithm that assigns the clusters. Python has the 'dendrogram'\n###and 'linkage' functions available from scipy.cluster.hierarchy which we will use.","metadata":{"papermill":{"duration":0.073231,"end_time":"2022-07-03T10:32:54.904343","exception":false,"start_time":"2022-07-03T10:32:54.831112","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nplt.figure(figsize=(10,10))\ndendrogram(linkage(data ,method='ward'), truncate_mode='level', p=3 )\nplt.axhline(y=4, label='threshold', color='red', lw=3)\nplt.title='Dendrogram'\nplt.legend(loc=6)\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2022-07-03T10:32:55.054354Z","iopub.status.busy":"2022-07-03T10:32:55.053639Z","iopub.status.idle":"2022-07-03T10:32:55.335126Z","shell.execute_reply":"2022-07-03T10:32:55.334254Z"},"papermill":{"duration":0.359279,"end_time":"2022-07-03T10:32:55.337264","exception":false,"start_time":"2022-07-03T10:32:54.977985","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Number of observations per Cluster\nprint(reduced2.Hierarchical_Clusters.value_counts())","metadata":{"execution":{"iopub.execute_input":"2022-07-03T10:32:55.638752Z","iopub.status.busy":"2022-07-03T10:32:55.638438Z","iopub.status.idle":"2022-07-03T10:32:55.645736Z","shell.execute_reply":"2022-07-03T10:32:55.644333Z"},"papermill":{"duration":0.085705,"end_time":"2022-07-03T10:32:55.647800","exception":false,"start_time":"2022-07-03T10:32:55.562095","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}